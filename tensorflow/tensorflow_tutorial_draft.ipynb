{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TENSORFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/get_started/get_started#tensorflow_core_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#High level API (for dummies)\n",
    "highlevel = tf.contrib.learn\n",
    "help(highlevel)\n",
    "#Here we will learn TensorFlow Core API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor** is a set of primitive values shaped into any array any dimensions. Rank of tensor is number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tensors examples\n",
    "3 # a rank 0 tensor; this is a scalar with shape []\n",
    "[1. ,2., 3.] # a rank 1 tensor; this is a vector with shape [3]\n",
    "[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow Core programs as consisting of two discrete sections:\n",
    "\n",
    "1. Building the computational graph\n",
    "2. Running the computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A **computational graph** is a series of TensorFlow operations arranged into a graph of nodes\n",
    " \n",
    " To actually **evaluate** the nodes, we must run the computational graph within a session. A **session** encapsulates the control and state of the TensorFlow runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) #also float\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run([node1, node2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "print(\"node3: \", node3)\n",
    "print(\"sess.run(node3): \",sess.run(node3))\n",
    "\n",
    "res = sess.run(node3)\n",
    "print res, type(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph can be parameterized to accept external inputs, known as placeholders. A placeholder is a **promise** to provide a value later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n",
    "#the above lines is similar to function/lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(adder_node, {a: 3, b:4.5}))\n",
    "print(sess.run(adder_node, {a: [1,3], b: [2, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_and_triple = adder_node * 3.\n",
    "print(sess.run(add_and_triple, {a: 3, b:4.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#variables\n",
    "W = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "y_pred = W * x + b\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(y_pred, {x:[1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(y_pred - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fixW = tf.assign(W, [-1.])   #`assign` allows to change variable\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "sess.run(init) # reset values to incorrect defaults.\n",
    "for _ in range(1000):\n",
    "    sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "\n",
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The completed trainable linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Model parameters\n",
    "W = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "# Model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "y = tf.placeholder(tf.float32)\n",
    "# loss\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "# training data\n",
    "x_train = [1,2,3,4]\n",
    "y_train = [0,-1,-2,-3]\n",
    "# training loop\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) # reset values to wrong\n",
    "for _ in xrange(10000):\n",
    "    sess.run(train, {x:x_train, y:y_train})\n",
    "    curr_W, curr_b, curr_loss  = sess.run([W, b, loss], {x:x_train, y:y_train})\n",
    "    print(\"W: %s b: %s loss: %s\\r\"%(curr_W, curr_b, curr_loss)),\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss  = sess.run([W, b, loss], {x:x_train, y:y_train})\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST For ML Beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"shape of train data: {}\".format(mnist.train.images.shape)\n",
    "print \"shape of train labels: {}\".format(mnist.train.labels.shape)\n",
    "print \"shape of test data: {}\".format(mnist.test.images.shape)\n",
    "print \"shape of test labels: {}\".format(mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to visualization of  \n",
    "def printDigit(matrix, hot_label):\n",
    "    matrix = matrix.reshape((28, 28))\n",
    "    label = np.where(hot_label==1)[0][0]  #decode hot-encoded label\n",
    "    plt.figure(figsize = (1.5,1.5))\n",
    "    plt.title('Label is {label}'.format(label=label))\n",
    "    plt.imshow(matrix, cmap='plasma')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    printDigit(mnist.test.images[i+1000], mnist.test.labels[i+1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename='Screenshot_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename='Screenshot_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784]) # None means that a dimension can be of any length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that W has a shape of [784, 10] because we want to multiply the 784-dimensional image vectors by it to produce 10-dimensional vectors of evidence for the difference classes. b has a shape of [10] so we can add it to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#our model\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss function is cross entropy (like log loss)\n",
    "#https://docs.google.com/a/iponweb.net/spreadsheets/d/1pW_Tyb-5sYwIfdseWeir0R23pI9SfEtOVao8p8AMbEs/edit?usp=sharing\n",
    "y_ = tf.placeholder(tf.float32, [None, 10]) #true answer\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "#such implementation is unstable becouse log(0) is undefined\n",
    "#so, there is build in function in tensorflow\n",
    "#tf.nn.softmax_cross_entropy_with_logits() \n",
    "#     https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimisation\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(1000)\n",
    "    sess.run([cross_entropy,train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    print \"{}\\r\".format(cross_entropy.eval(feed_dict={x: batch_xs, y_: batch_ys})),\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Deep MNIST for Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "printDigit(mnist.test.images[77], mnist.test.labels[77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])  #features\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])  #true targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 linear layer (it means there is no hidden layers)\n",
    "W = tf.Variable(tf.zeros([784,10]))  #786 - number of features, 10 - outout dimension\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "y = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss function (average value of cross entropy for all objects)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step   #it is operation\n",
    "             #you can run it using command train_step.run(session = sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#estimate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "average_train_losses = []; average_test_losses = []\n",
    "accuracy_train = []; accuracy_test = []\n",
    "steps = []\n",
    "\n",
    "\n",
    "num_steps = 50001\n",
    "for step in tqdm_notebook(range(num_steps)):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    _ = sess.run(train_step, feed_dict={x: batch[0], y_: batch[1]})\n",
    "    \n",
    "    #collect stats\n",
    "    period = num_steps/20 #20 points\n",
    "    if step % period == 0:\n",
    "        if step > 0:\n",
    "            #losts\n",
    "            loss_train = sess.run(cross_entropy, feed_dict={x: mnist.train.images, y_: mnist.train.labels})\n",
    "            average_train_losses.append(loss_train)\n",
    "            loss_test = sess.run(cross_entropy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "            average_test_losses.append(loss_test)\n",
    "            \n",
    "            #accuracy\n",
    "            accuracy_train_one = accuracy.eval(feed_dict={x: mnist.train.images, y_: mnist.train.labels})\n",
    "            accuracy_train.append(accuracy_train_one)\n",
    "            accuracy_test_one = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "            accuracy_test.append(accuracy_test_one)\n",
    "            \n",
    "            steps.append(step)\n",
    "            \n",
    "    #print \"progress {:2.2%}\\r\".format(float(step)/num_steps), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,4))\n",
    "plt.plot(steps, average_train_losses,'.-', c='g')\n",
    "plt.plot(steps, average_test_losses, '.-', c='r')\n",
    "plt.grid()\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,4))\n",
    "plt.plot(steps, accuracy_train,'.-', c='g')\n",
    "plt.plot(steps, accuracy_test, '.-', c='r')\n",
    "plt.grid()\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#final accuracy\n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multilayer Convolutional Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight inotialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, mean=0.0, stddev=0.1)   #init by random values ~N(0.0,0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)   #init by constant\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convolution ad pooling\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First Convolutional Layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])     #32 maps, tune\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "#-1 - is the special value, the size of that dimension is computed so that the total size remains constant\n",
    "#28,28 - width and height\n",
    "#1 - RGB numbers (we have black and white pics, therefore we have only 1 number)\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# second convolutional layer\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])    #64 maps, tune\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)  #28*28 --> 14*14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# densely connected layer\n",
    " \n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# readout layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train and Evaluate the Model\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50) \n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FOR KAGGLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://www.tensorflow.org/get_started/mnist/pros#f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "#from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((42000, 784), (42000,), (28000, 784))\n"
     ]
    }
   ],
   "source": [
    "X = train.drop('label', axis = 1).values\n",
    "y = train['label'].values\n",
    "x_test_to_submit = test.values\n",
    "del train, test\n",
    "print(X.shape, y.shape, x_test_to_submit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to One-Hot-Encoding target variable\n",
    "#example: 3 ---> [0,0,0,1,0,0,0,0,0,0]\n",
    "def encodeTarget(Y):\n",
    "    temp = np.zeros((y.size, y.max()+1))\n",
    "    temp[np.arange(y.size), y] = 1\n",
    "    return temp\n",
    "y = encodeTarget(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function for digits visualization  \n",
    "def printDigit(matrix, hot_label):\n",
    "    matrix = matrix.reshape((28, 28))\n",
    "    label = np.where(hot_label==1)[0][0]  #decode hot-encoded label\n",
    "    plt.figure(figsize = (1.5,1.5))\n",
    "    plt.title('Label is {label}'.format(label=label))\n",
    "    plt.imshow(matrix, cmap='plasma')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHcAAACACAYAAAAxrvYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuTHGmxtjvLkxxpsbY/4PvHiysoN7kJ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ffb7ac090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHcAAACACAYAAAAxrvYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf9hdS21WvOUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ffb7214d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printDigit(X[7,:], y[7])\n",
    "printDigit(X[777,:], y[777])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])  #features\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])  #true targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight inotialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, mean=0.0, stddev=0.1)   #init by random values ~N(0.0,0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)   #init by constant\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convolution and pooling\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First Convolutional Layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])     #32 maps, tune\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "#-1 - is the special value, the size of that dimension is computed so that the total size remains constant\n",
    "#28,28 - width and height\n",
    "#1 - RGB numbers (we have black and white pics, therefore we have only 1 number)\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# second convolutional layer\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])    #64 maps, tune\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)  #28*28 --> 14*14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# densely connected layer\n",
    " \n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# readout layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get next batch\n",
    "def next_batch(batch_size):\n",
    "    global data_index\n",
    "    batch = X[data_index:data_index+batch_size,:]\n",
    "    labels = y[data_index:data_index+batch_size,:]\n",
    "    return (batch, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.08\n",
      "step 100, training accuracy 1\n",
      "step 200, training accuracy 1\n",
      "step 300, training accuracy 1\n",
      "step 400, training accuracy 1\n",
      "step 500, training accuracy 1\n",
      "step 600, training accuracy 1\n",
      "step 700, training accuracy 1\n",
      "step 800, training accuracy 1\n",
      "step 900, training accuracy 1\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate the Model\n",
    "data_index = 0\n",
    "batch_size = 25\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(1000):\n",
    "    batch = next_batch(batch_size)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "#print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "#    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predict by batch (without such tric, Memory Error raises):\n",
    "size = 100\n",
    "batches_generator = (x_test_to_submit[i:i + size] for i in range(0, len(x_test_to_submit), size))\n",
    "predictions = []\n",
    "y_pred_digits = tf.argmax(y_conv,1)\n",
    "for test_batch in batches_generator:\n",
    "    predictions.extend(y_pred_digits.eval(feed_dict={x:test_batch, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save results\n",
    "header = \"ImageId,Label\\n\"\n",
    "with open(\"results.csv\", 'w') as f:\n",
    "    f.write(header)\n",
    "    f.write(\"\\n\".join((\"{},{}\".format(ind+1, dig) for ind,dig in enumerate(predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
