{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TENSORFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/get_started/get_started#tensorflow_core_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#High level API (for dummies)\n",
    "highlevel = tf.contrib.learn\n",
    "help(highlevel)\n",
    "#Here we will learn TensorFlow Core API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor** is a set of primitive values shaped into any array any dimensions. Rank of tensor is number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensors examples\n",
    "3 # a rank 0 tensor; this is a scalar with shape []\n",
    "[1. ,2., 3.] # a rank 1 tensor; this is a vector with shape [3]\n",
    "[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow Core programs as consisting of two discrete sections:\n",
    "\n",
    "1. Building the computational graph\n",
    "2. Running the computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A **computational graph** is a series of TensorFlow operations arranged into a graph of nodes\n",
    " \n",
    " To actually **evaluate** the nodes, we must run the computational graph within a session. A **session** encapsulates the control and state of the TensorFlow runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) #also float\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run([node1, node2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "print(\"node3: \", node3)\n",
    "print(\"sess.run(node3): \",sess.run(node3))\n",
    "\n",
    "res = sess.run(node3)\n",
    "print res, type(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph can be parameterized to accept external inputs, known as placeholders. A placeholder is a **promise** to provide a value later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n",
    "#the above lines is similar to function/lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(adder_node, {a: 3, b:4.5}))\n",
    "print(sess.run(adder_node, {a: [1,3], b: [2, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_and_triple = adder_node * 3.\n",
    "print(sess.run(add_and_triple, {a: 3, b:4.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "W = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "y_pred = W * x + b\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(y_pred, {x:[1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(y_pred - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixW = tf.assign(W, [-1.])   #`assign` allows to change variable\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "sess.run(init) # reset values to incorrect defaults.\n",
    "for _ in range(1000):\n",
    "    sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "\n",
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The completed trainable linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Model parameters\n",
    "W = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "# Model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "y = tf.placeholder(tf.float32)\n",
    "# loss\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "# training data\n",
    "x_train = [1,2,3,4]\n",
    "y_train = [0,-1,-2,-3]\n",
    "# training loop\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) # reset values to wrong\n",
    "for _ in xrange(10000):\n",
    "    sess.run(train, {x:x_train, y:y_train})\n",
    "    curr_W, curr_b, curr_loss  = sess.run([W, b, loss], {x:x_train, y:y_train})\n",
    "    print(\"W: %s b: %s loss: %s\\r\"%(curr_W, curr_b, curr_loss)),\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss  = sess.run([W, b, loss], {x:x_train, y:y_train})\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST For ML Beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"shape of train data: {}\".format(mnist.train.images.shape)\n",
    "print \"shape of train labels: {}\".format(mnist.train.labels.shape)\n",
    "print \"shape of test data: {}\".format(mnist.test.images.shape)\n",
    "print \"shape of test labels: {}\".format(mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to visualization of  \n",
    "def printDigit(matrix, hot_label):\n",
    "    matrix = matrix.reshape((28, 28))\n",
    "    label = np.where(hot_label==1)[0][0]  #decode hot-encoded label\n",
    "    plt.figure(figsize = (1.5,1.5))\n",
    "    plt.title('Label is {label}'.format(label=label))\n",
    "    plt.imshow(matrix, cmap='plasma')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    printDigit(mnist.test.images[i+1000], mnist.test.labels[i+1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='Screenshot_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='Screenshot_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784]) # None means that a dimension can be of any length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that W has a shape of [784, 10] because we want to multiply the 784-dimensional image vectors by it to produce 10-dimensional vectors of evidence for the difference classes. b has a shape of [10] so we can add it to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#our model\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss function is cross entropy (like log loss)\n",
    "#https://docs.google.com/a/iponweb.net/spreadsheets/d/1pW_Tyb-5sYwIfdseWeir0R23pI9SfEtOVao8p8AMbEs/edit?usp=sharing\n",
    "y_ = tf.placeholder(tf.float32, [None, 10]) #true answer\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "#such implementation is unstable becouse log(0) is undefined\n",
    "#so, there is build in function in tensorflow\n",
    "#tf.nn.softmax_cross_entropy_with_logits() \n",
    "#     https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimisation\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(1000)\n",
    "    sess.run([cross_entropy,train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    print \"{}\\r\".format(cross_entropy.eval(feed_dict={x: batch_xs, y_: batch_ys})),\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Deep MNIST for Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHcAAACACAYAAAAxrvYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3108d006d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printDigit(mnist.test.images[77], mnist.test.labels[77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])  #features\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])  #true targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 linear layer (it means there is no hidden layers)\n",
    "W = tf.Variable(tf.zeros([784,10]))  #786 - number of features, 10 - outout dimension\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "y = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss function (average value of cross entropy for all objects)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step   #it is operation\n",
    "             #you can run it using command train_step.run(session = sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "average_train_losses = []; average_test_losses = []\n",
    "accuracy_train = []; accuracy_test = []\n",
    "steps = []\n",
    "\n",
    "\n",
    "num_steps = 50001\n",
    "for step in tqdm_notebook(range(num_steps)):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    _ = sess.run(train_step, feed_dict={x: batch[0], y_: batch[1]})\n",
    "    \n",
    "    #collect stats\n",
    "    period = num_steps/20 #20 points\n",
    "    if step % period == 0:\n",
    "        if step > 0:\n",
    "            #losts\n",
    "            loss_train = sess.run(cross_entropy, feed_dict={x: mnist.train.images, y_: mnist.train.labels})\n",
    "            average_train_losses.append(loss_train)\n",
    "            loss_test = sess.run(cross_entropy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "            average_test_losses.append(loss_test)\n",
    "            \n",
    "            #accuracy\n",
    "            accuracy_train_one = accuracy.eval(feed_dict={x: mnist.train.images, y_: mnist.train.labels})\n",
    "            accuracy_train.append(accuracy_train_one)\n",
    "            accuracy_test_one = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "            accuracy_test.append(accuracy_test_one)\n",
    "            \n",
    "            steps.append(step)\n",
    "            \n",
    "    #print \"progress {:2.2%}\\r\".format(float(step)/num_steps), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,4))\n",
    "plt.plot(steps, average_train_losses,'.-', c='g')\n",
    "plt.plot(steps, average_test_losses, '.-', c='r')\n",
    "plt.grid()\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,4))\n",
    "plt.plot(steps, accuracy_train,'.-', c='g')\n",
    "plt.plot(steps, accuracy_test, '.-', c='r')\n",
    "plt.grid()\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final accuracy\n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multilayer Convolutional Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight inotialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, mean=0.0, stddev=0.1)   #init by random values ~N(0.0,0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)   #init by constant\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution ad pooling\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Convolutional Layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])     #32 maps, tune\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "#-1 - is the special value, the size of that dimension is computed so that the total size remains constant\n",
    "#28,28 - width and height\n",
    "#1 - RGB numbers (we have black and white pics, therefore we have only 1 number)\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second convolutional layer\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])    #64 maps, tune\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)  #28*28 --> 14*14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# densely connected layer\n",
    " \n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# readout layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate the Model\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50) \n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FOR KAGGLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://www.tensorflow.org/get_started/mnist/pros#f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SETTINGS:\n",
    "\n",
    "NUM_FILTERS_CONV_1 = 32*2\n",
    "NUM_FILTERS_CONV_2 = 64*2\n",
    "NUM_FILTERS_CONV_3 = 128*2\n",
    "NUM_READOUT_NEURONS = 2048*2\n",
    "\n",
    "KEEP_PROB = 0.4\n",
    "LEARNING_RATE = 1.0e-5\n",
    "TEST_SIZE = 0.001     #0.0002\n",
    "NUMBER_STEPS = 500000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "thersold_good_prediction = 0.999999999\n",
    "NUMBER_STEPS_TEST = 50000\n",
    "AFTER_NUM_STEPS_APPEND_TEST_DATA = 50000 #every the number ew append test date to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn import model_selection\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "#from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((41958, 784), (41958, 10), (28000, 784))\n"
     ]
    }
   ],
   "source": [
    "X = train.drop('label', axis = 1).values\n",
    "y = train['label'].values\n",
    "\n",
    "#function to One-Hot-Encoding target variable\n",
    "#example: 3 ---> [0,0,0,1,0,0,0,0,0,0]\n",
    "def encodeTarget(Y):\n",
    "    temp = np.zeros((y.size, y.max()+1))\n",
    "    temp[np.arange(y.size), y] = 1\n",
    "    return temp\n",
    "\n",
    "y = encodeTarget(y)\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size = TEST_SIZE)\n",
    "x_test_to_submit = test.values\n",
    "del train, test, X, y\n",
    "print(X_train.shape, y_train.shape, x_test_to_submit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function for digits visualization  \n",
    "def printDigit(matrix, hot_label):\n",
    "    matrix = matrix.reshape((28, 28))\n",
    "    label = np.where(hot_label==1)[0][0]  #decode hot-encoded label\n",
    "    plt.figure(figsize = (1.5,1.5))\n",
    "    plt.title('Label is {label}'.format(label=label))\n",
    "    plt.imshow(matrix, cmap='plasma')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHcAAACACAYAAAAxrvYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f449bd067d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHcAAACACAYAAAAxrvYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncz0mmOsxwVyP+T9XGv01EaNLMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f449bd06e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printDigit(X_train[7,:], y_train[7])\n",
    "printDigit(X_train[777,:], y_train[777])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])  #features\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])  #true targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight inotialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, mean=0.0, stddev=0.1)   #init by random values ~N(0.0,0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)   #init by constant\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First Convolutional Layer\n",
    "W_conv1 = weight_variable([5, 5, 1, NUM_FILTERS_CONV_1])     #32 maps, tune\n",
    "b_conv1 = bias_variable([NUM_FILTERS_CONV_1])\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "#-1 - is the special value, the size of that dimension is computed so that the total size remains constant\n",
    "#28,28 - width and height\n",
    "#1 - RGB numbers (we have black and white pics, therefore we have only 1 number)\n",
    "\n",
    "#convolution layer, activation function and pooling layer\n",
    "h_conv1 = tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_relu1 = tf.nn.relu(h_conv1 + b_conv1)\n",
    "h_pool1 = tf.nn.max_pool(h_relu1, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME') #28*28 --> 14*14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second convolutional layer\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, NUM_FILTERS_CONV_1, NUM_FILTERS_CONV_2])\n",
    "b_conv2 = bias_variable([NUM_FILTERS_CONV_2])\n",
    "a\n",
    "h_conv2 = tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_relu2 = tf.nn.relu(h_conv2 + b_conv2)\n",
    "h_pool2 = tf.nn.max_pool(h_relu2, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME') #14*14 --> 7*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# third convolutional layer\n",
    "\n",
    "W_conv3 = weight_variable([3, 3, NUM_FILTERS_CONV_2, NUM_FILTERS_CONV_3])\n",
    "b_conv3 = bias_variable([NUM_FILTERS_CONV_3])\n",
    "\n",
    "h_conv3 = tf.nn.conv2d(h_pool2, W_conv3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "h_relu3 = tf.nn.relu(h_conv3 + b_conv3)\n",
    "h_pool3 = tf.nn.max_pool(h_relu3, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME') #7*7 --> 4*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TESTING\n",
    "\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "#batch = next_batch(BATCH_SIZE)\n",
    "#h_pool3.eval(feed_dict={x:batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# densely connected layer\n",
    " \n",
    "W_fc1 = weight_variable([4 * 4 * NUM_FILTERS_CONV_3, NUM_READOUT_NEURONS])\n",
    "b_fc1 = bias_variable([NUM_READOUT_NEURONS])\n",
    "\n",
    "h_pool3_flat = tf.reshape(h_pool3, [-1, 4*4*NUM_FILTERS_CONV_3])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readout layer\n",
    "W_fc2 = weight_variable([NUM_READOUT_NEURONS, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(batch_size):\n",
    "    #get next batch\n",
    "    global data_index\n",
    "    batch = X_train[data_index:data_index+batch_size,:]\n",
    "    labels = y_train[data_index:data_index+batch_size,:]\n",
    "    data_index = (data_index + batch_size) % (X_train.shape[0])\n",
    "    return (batch, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch_from_test(batch_size, X_add , y_add):\n",
    "    #get next batch\n",
    "    global data_index_test\n",
    "    batch = X_add[data_index_test:data_index_test+batch_size,:]\n",
    "    labels = y_add[data_index_test:data_index_test+batch_size,:]\n",
    "    data_index_test = (data_index_test + batch_size) % (X_train.shape[0])\n",
    "    return (batch, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_test_data_and_extract_well_predicted():\n",
    "    #idea:\n",
    "    #if prelimenary trained algo show very high probability a digits belong to the class, \n",
    "    # we'll append it to training sample and retrain the algo\n",
    "    \n",
    "    size = 100\n",
    "    batches_generator = (x_test_to_submit[i:i + size] for i in range(0, len(x_test_to_submit), size))\n",
    "    predictions = []\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    y_pred_digits = tf.argmax(y_conv,1)\n",
    "       \n",
    "    for test_batch in batches_generator:\n",
    "        predicted = y_conv.eval(feed_dict={x:test_batch, keep_prob: 1.0})\n",
    "        predictions.extend(predicted)\n",
    "    \n",
    "    predictions = np.array(predictions)           # to numpy array\n",
    "    predictions = tf.nn.softmax(predictions).eval()\n",
    "    predictions = (predictions > thersold_good_prediction).astype(int)    #transform to [0,0,0,1,0,0,]\n",
    "                                                                          #if there is no outstanding value,\n",
    "                                                                          #predicted will consist of zeros\n",
    "    bool_values = np.any(predictions, axis = 1)   # True means there is non-zero element\n",
    "                                                  # False means all elements equal zeros\n",
    "    indexes = np.argwhere(bool_values).ravel()     # indexes of \"True\"\n",
    "    return x_test_to_submit[indexes], predictions[indexes]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train and Evaluate the Model\n",
    "data_index = 0\n",
    "data_index_test = 0\n",
    "\n",
    "stats = []\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in tqdm_notebook(range(NUMBER_STEPS)):\n",
    "    batch = next_batch(BATCH_SIZE)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        valid_accuracy = accuracy.eval(feed_dict={x:X_valid, y_: y_valid, keep_prob: 1.0})\n",
    "        stats.append([i,train_accuracy,valid_accuracy])\n",
    "        print(\"step %d, training/valid accuracy %.3g\\t%.3g\"%(i, train_accuracy, valid_accuracy))\n",
    "    \n",
    "    # append test data to train\n",
    "    if i%AFTER_NUM_STEPS_APPEND_TEST_DATA == 0 and i!=0:  \n",
    "        X_add, y_add = mark_test_data_and_extract_well_predicted()\n",
    "        for j in tqdm_notebook(range(NUMBER_STEPS_TEST)):\n",
    "            batch_test =  next_batch_from_test(BATCH_SIZE, X_add , y_add)\n",
    "            if j%100 == 0:\n",
    "                train_accuracy = accuracy.eval(feed_dict={x:batch_test[0], y_: batch_test[1], keep_prob: 1.0})\n",
    "                valid_accuracy = accuracy.eval(feed_dict={x:X_valid, y_: y_valid, keep_prob: 1.0})\n",
    "                print(\"test data, step %d, training/valid accuracy %.3g\\t%.3g\"%(j, train_accuracy, valid_accuracy))\n",
    "\n",
    "            train_step.run(feed_dict={x: batch_test[0], y_: batch_test[1], keep_prob: KEEP_PROB})\n",
    "    \n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: KEEP_PROB})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot chartsz\n",
    "plt.figure(figsize=(10,5))\n",
    "steps = [a for a,b,c in stats][1:]\n",
    "train_acc = [b for a,b,c in stats][1:]\n",
    "test_acc = [c for a,b,c in stats][1:]\n",
    "\n",
    "plt.plot(steps,train_acc, label = \"train\", c='b')\n",
    "plt.plot(steps,test_acc, label = \"test\", c='r')\n",
    "plt.grid(True)\n",
    "plt.title(\"accuracy VS step\", fontsize = 14)\n",
    "plt.ylabel(\"accuracy\", fontsize = 13)\n",
    "plt.xlabel(\"step\", fontsize = 13)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict by batch (without such tric, Memory Error raises):\n",
    "size = 100\n",
    "batches_generator = (x_test_to_submit[i:i + size] for i in range(0, len(x_test_to_submit), size))\n",
    "predictions = []\n",
    "y_pred_digits = tf.argmax(y_conv,1)\n",
    "for test_batch in batches_generator:\n",
    "    predictions.extend(y_pred_digits.eval(feed_dict={x:test_batch, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #save results\n",
    "    header = \"ImageId,Label\\n\"\n",
    "    with open(\"results.csv\", 'w') as f:\n",
    "        f.write(header)\n",
    "        f.write(\"\\n\".join((\"{},{}\".format(ind+1, dig) for ind,dig in enumerate(predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {
    "07638ddd8be64205a0d2f6d30e1812f9": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "0c36e53e48d34ed2b19e2434f4fa6295": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "14f09f980dfc4482b0d8394f16634b27": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "2b8a042588ba45bf83ed2c1426513e59": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "4894fa1147334479af4e6d6d8f08d968": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "58a81c1e038f42c3acc2bf21ca52d715": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "683e7eebca66464083d7f219a09d81f5": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "6ecab47ba3734a10a5c8a96691420b36": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "80d9ba3f53e94f30a316200100b470bd": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "80f124cec8e341dfb5ea62079130ab4d": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "a9184bcae1574edb9dc3a8ca635c09d4": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "cbf4998877d04d08816cefdf85e4cfce": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "ddfd72f4132f401ebc24fe65996b70bc": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    },
    "f2cccc469610427ab66cd46367f0086e": {
     "views": [
      {
       "cell_index": 104
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
